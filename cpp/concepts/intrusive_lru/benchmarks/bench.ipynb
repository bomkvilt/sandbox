{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pathlib\n",
    "import re\n",
    "import subprocess\n",
    "\n",
    "import polars as pl\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_benchmark_results() -> pl.DataFrame:\n",
    "    benchmark = subprocess.run(\n",
    "        \" \".join(\n",
    "            [\n",
    "                *[\"bazelisk\", \"run\"],\n",
    "                *[\"-c\", \"opt\"],\n",
    "                *[\":bench\"],\n",
    "                \"--\",\n",
    "                # do several runs\n",
    "                \"--benchmark_enable_random_interleaving=true\",\n",
    "                \"--benchmark_report_aggregates_only=false\",\n",
    "                \"--benchmark_repetitions=50\",\n",
    "                # report in json format\n",
    "                \"--benchmark_format=json\",\n",
    "            ]\n",
    "        ),\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.PIPE,\n",
    "        cwd=pathlib.Path(os.getcwd()).parent,\n",
    "        shell=True,\n",
    "        text=True,\n",
    "    )\n",
    "\n",
    "    if benchmark.returncode != 0:\n",
    "        error = Exception(\"Benchmark failed\")\n",
    "        error.add_note(benchmark.stderr)\n",
    "        raise error\n",
    "    return pl.DataFrame(json.loads(benchmark.stdout)[\"benchmarks\"])\n",
    "\n",
    "\n",
    "benchmark = get_benchmark_results()\n",
    "benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_run_name(run_name: str | None) -> dict[str, str | None]:\n",
    "    # Example: LRUCacheBench<std, hit>::put/iterations:100/manual_time\n",
    "    if (run_name is not None) and (m := re.match(r\"^LRUCacheBench<([^,]+), ([^,]+), ([^>]+)>::(\\w+)\", run_name)):\n",
    "        version, allocator, hit_mode, function = m.groups()\n",
    "        return {\"version\": version, \"allocator\": allocator, \"hit_mode\": hit_mode, \"function\": function}\n",
    "    return {}\n",
    "\n",
    "\n",
    "data = (\n",
    "    benchmark.select(\n",
    "        pl.col(\"run_name\").alias(\"name\"),\n",
    "        pl.col(\"run_type\"),\n",
    "        pl.col(\"real_time\"),\n",
    "        pl.col(\"time_unit\"),\n",
    "    )\n",
    "    .filter(pl.col(\"name\").str.starts_with(\"LRUCacheBench\"))\n",
    "    .filter(pl.col(\"run_type\") == \"iteration\")\n",
    "    .with_columns(\n",
    "        pl.col(\"name\").map_elements(\n",
    "            parse_run_name,\n",
    "            return_dtype=pl.Struct({\"version\": pl.Utf8, \"allocator\": pl.Utf8, \"hit_mode\": pl.Utf8, \"function\": pl.Utf8}),\n",
    "        )\n",
    "    )\n",
    "    .unnest(\"name\")\n",
    "    .with_columns(\n",
    "        pl.concat_str(\n",
    "            [\n",
    "                pl.col(\"version\"),\n",
    "                pl.lit(\" : \"),\n",
    "                pl.col(\"allocator\"),\n",
    "            ]\n",
    "        ).alias(\"preset\")\n",
    "    )\n",
    "    .sort(\"function\", \"hit_mode\", \"version\", \"allocator\")\n",
    ")\n",
    "assert data[\"time_unit\"].unique().to_list() == [\"ns\"]\n",
    "\n",
    "fig = px.box(\n",
    "    data,\n",
    "    x=\"hit_mode\",\n",
    "    y=\"real_time\",\n",
    "    color=\"preset\",\n",
    "    facet_col=\"function\",\n",
    "    title=\"Average execution time per operation, ns\",\n",
    ")\n",
    "fig.update_yaxes(matches=None)\n",
    "fig.for_each_yaxis(lambda yaxis: yaxis.update(showticklabels=True))\n",
    "\n",
    "fig.write_html(\"bench.html\")\n",
    "fig.write_image(\"bench.png\", width=1920, height=1080)\n",
    "fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
